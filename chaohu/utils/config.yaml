# Environment name
chaohu:
  # strategy
  VDN:
    # agent class
    agent_class: VDN
    # if is multi-agent
    if_mac: True
    # if use recurrent
    if_recurrent: False
    # recurrent sequence length
    seq_len: 3
    # dimension of hidden layers
    net_dim: 128
    # number of network layers
    num_layer: 3
    # if use dueling layer
    if_dueling: True

    # training steps
    total_episodes: 5000
    # pre-sampling steps
    pre_episodes: 100
    # exploration events
    explore_events: 20
    # exploration step
    explore_step: 36
    # epsilon-greedy noise
    epsilon_decay: 0.999
    epsilon_min: 0.1

    # maximum capacity for the replay buffer
    max_capacity: 250000
    # batch size of the training data
    batch_size: 128
    # discouted rate
    gamma: 0.95
    # learning rate
    learning_rate: 0.0001
    # update tau for target network
    update_interval: 0.05
    # repeatedly update network using ReplayBuffer
    repeat_times: 2
    # loss function
    loss_function: MeanSquaredError
    # optimizer
    optimizer: Adam

    # evaluation events
    eval_events: 1
    # evaluate the agent per eval_gap
    eval_gap: 10
    # the working directory
    cwd: ./model/VDN
    # if remove the cwd or keep it
    if_remove: True
